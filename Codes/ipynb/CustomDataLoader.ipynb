{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c65bacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import data_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd567438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, case, port, line_model, input_cols, output_col, indices, device):\n",
    "        # case: simulation case name in ../Data/\n",
    "        # port: the number of ports in the line model\n",
    "        # line_model: name of line model in Tml Simulation\n",
    "        # input_cols: ['W', 'Trap', 'Length'], for example\n",
    "        # outpul_col: ['A(1,2)'] or ['P(2,4)'], for example\n",
    "        \n",
    "        self.case = case\n",
    "        self.port = port\n",
    "        self.home_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "        self.result_dir = os.path.join(self.home_dir, 'Data', '%s' % self.case)\n",
    "        self.config_dir = os.path.join(self.home_dir, 'Data', 'Config', '%s.json' % line_model)\n",
    "        \n",
    "        # define df headers\n",
    "        self.snp_headers = []\n",
    "        for i in range(port):\n",
    "            for j in range(port):\n",
    "                for s in 'SR', 'SI':\n",
    "                    self.snp_headers.append('%s(%d,%d)' % (s, i+1, j+1))\n",
    "        \n",
    "        # define input cols and parameters input\n",
    "        self.input_cols = input_cols\n",
    "        with open(self.config_dir) as f:\n",
    "            self.config = json.load(f)\n",
    "        self.parameters_df = data_parser.read_input_feature_xlsx(case, port).loc[indices][input_cols]\n",
    "        for input_col in input_cols:\n",
    "            self.parameters_df[input_col] = (self.parameters_df[input_col] - self.config[input_col]['min']) / (self.config[input_col]['max'] - self.config[input_col]['min'])\n",
    "        \n",
    "        # define output col\n",
    "        # if output col is P(i,j), output is [sinP, cosP]\n",
    "        self.output_col = output_col\n",
    "        self.index = [eval(i) for i in re.findall(r\"(\\d)\", self.output_col)] # get output indices\n",
    "        if 'A' in self.output_col:\n",
    "            self.index = ['A'] + self.index\n",
    "        elif 'P' in self.output_col:\n",
    "            self.index = ['P'] + self.index\n",
    "        elif 'SR' in self.output_col:\n",
    "            self.index = ['SR'] + self.index\n",
    "        elif 'SI' in self.output_col:\n",
    "            self.index = ['SI'] + self.index\n",
    "        else:\n",
    "            raise ValueError('Output col must be A(i,j) or P(i,j)!')\n",
    "            \n",
    "        # define device\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.parameters_df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        idx = self.parameters_df.index[idx]\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(self.result_dir, idx, 'RLGC', 'TransmissionLine.s%dp' % self.port), skiprows=port+3, delim_whitespace=True, header=None).loc[:, 1:]\n",
    "        df.columns = self.snp_headers\n",
    "        \n",
    "        # process input\n",
    "        parameters = torch.Tensor(self.parameters_df.loc[idx])\n",
    "        \n",
    "        # process output\n",
    "        if self.index[0] == 'A':\n",
    "            output = np.sqrt(df['SR(%d,%d)'% (self.index[1], self.index[2])] ** 2 + df['SI(%d,%d)'% (self.index[1], self.index[2])] ** 2)\n",
    "            output = torch.Tensor(output)\n",
    "        elif self.index[0] == 'P':\n",
    "            phase = np.arctan2(df['SI(%d,%d)'% (self.index[1], self.index[2])] , df['SR(%d,%d)'% (self.index[1], self.index[2])])\n",
    "            sinP = np.sin(phase)\n",
    "            cosP = np.cos(phase)\n",
    "            output = torch.Tensor([sinP, cosP])\n",
    "        elif self.index[0] == 'SR':\n",
    "            output = torch.Tensor(df['SR(%d,%d)'% (self.index[1], self.index[2])])\n",
    "        else: # self.index[0] == 'SI'\n",
    "            output = torch.Tensor(df['SI(%d,%d)'% (self.index[1], self.index[2])])\n",
    "        return parameters.to(self.device), output.to(self.device)\n",
    "\n",
    "def generate_indices(case, port,):\n",
    "    \n",
    "    current_dir = os.getcwd()\n",
    "    home_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "    data_dir = os.path.join(home_dir, 'Data')\n",
    "    result_dir = os.path.join(data_dir, '%s' % case)\n",
    "    keys = []\n",
    "    for dirs in os.listdir(result_dir):\n",
    "        if os.path.isdir(os.path.join(result_dir, dirs, 'RLGC')):\n",
    "            snp = 'TransmissionLine.s%dp' % port            \n",
    "            if os.path.exists(os.path.join(result_dir, dirs, 'RLGC', snp)):\n",
    "                keys.append(dirs)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc3f0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'Differential_Stripline_test'\n",
    "port = 4\n",
    "line_model = 'Stripline_Diff-Pair'\n",
    "input_cols = ['W', 'Trap', 'Length']\n",
    "dataname = '%s' %(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29063679",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = generate_indices(case, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1067bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the indices\n",
    "read_idx = False\n",
    "index_file = '../Data/Indices/index_%s.pkl' % dataname\n",
    "if read_idx == True:\n",
    "    with open(index_file, 'rb') as f:\n",
    "        indices = pickle.load(f)\n",
    "else:\n",
    "    random.seed(42)\n",
    "    np.random.shuffle(keys)\n",
    "    \n",
    "    # Split the indices into 80% training set, 10% testing set and 10% validation set\n",
    "    indices = {}\n",
    "    indices['train_idx'] = keys[:int(len(keys) * 0.8)]\n",
    "    indices['val_idx'] = keys[int(len(keys) * 0.8):int(len(keys) * 0.9)]\n",
    "    indices['test_idx'] = keys[int(len(keys) * 0.9):]\n",
    "\n",
    "    with open(index_file, 'wb') as f:\n",
    "        pickle.dump(indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89b4a856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(case, port, line_model, input_cols, 'A(1,1)', indices['train_idx'])\n",
    "parameters, output = train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbe75b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd386023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([64, 501])\n",
      "torch.Size([32, 501])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample in enumerate(train_dataloader):\n",
    "    X, y = sample\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c786b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
